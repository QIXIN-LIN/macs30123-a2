{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_survey(survey_path, sqs_url):\n",
    "    '''\n",
    "        Input:\n",
    "            survey_path (str): path to JSON survey data (e.g. ‘./survey.json’)\n",
    "            sqs_url (str): URL for SQS queue\n",
    "        Output:\n",
    "            StatusCode (int): indicating whether the survey was successfully \n",
    "            sent into the SQS queue (200) or not (0)\n",
    "    '''\n",
    "    # Load survey data from the file\n",
    "    with open(survey_path, 'r') as file:\n",
    "        survey_data = json.load(file)\n",
    "\n",
    "    # Create a boto3 client for SQS\n",
    "    sqs_client = boto3.client('sqs')\n",
    "\n",
    "    # Send the message to the SQS queue\n",
    "    try:\n",
    "        response = sqs_client.send_message(\n",
    "            QueueUrl=sqs_url,\n",
    "            MessageBody=json.dumps(survey_data)\n",
    "        )\n",
    "        return 200  # Successful status code\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to send message: {e}\")\n",
    "        return 0  # Failure status code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket a2q1-bucket created successfully.\n",
      "Error creating DynamoDB table: An error occurred (ResourceInUseException) when calling the CreateTable operation: Table already exists: a2q1-table\n"
     ]
    }
   ],
   "source": [
    "lambda_client = boto3.client('lambda')\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "# Define the bucket name (must be globally unique)\n",
    "bucket_name = 'a2q1-bucket'\n",
    "\n",
    "try:\n",
    "    # Create the S3 bucket\n",
    "    s3_client.create_bucket(Bucket=bucket_name)\n",
    "    print(f\"S3 bucket {bucket_name} created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating S3 bucket {bucket_name}: {str(e)}\")\n",
    "\n",
    "\n",
    "# Attempt to retrieve the IAM role\n",
    "try:\n",
    "    role = iam_client.get_role(RoleName='LabRole')\n",
    "    role_arn = role['Role']['Arn']\n",
    "except iam_client.exceptions.NoSuchEntityException:\n",
    "    print(\"Specified IAM role does not exist.\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving IAM role: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Initialize a DynamoDB client\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "dynamodb_client = boto3.client('dynamodb')\n",
    "\n",
    "# Define the table name\n",
    "table_name = 'a2q1-table'\n",
    "\n",
    "try: \n",
    "    # Create the DynamoDB table\n",
    "    table = dynamodb.create_table(\n",
    "        TableName=table_name,\n",
    "        KeySchema=[\n",
    "            {'AttributeName': 'user_id', 'KeyType': 'HASH'},  # Partition key\n",
    "            {'AttributeName': 'timestamp', 'KeyType': 'RANGE'}  # Sort key\n",
    "        ],\n",
    "        AttributeDefinitions=[\n",
    "            {'AttributeName': 'user_id', 'AttributeType': 'S'},\n",
    "            {'AttributeName': 'timestamp', 'AttributeType': 'S'}\n",
    "        ],\n",
    "        ProvisionedThroughput={\n",
    "            'ReadCapacityUnits': 1,\n",
    "            'WriteCapacityUnits': 1\n",
    "        }\n",
    "    )\n",
    "    table.meta.client.get_waiter('table_exists').wait(TableName=table_name)\n",
    "\n",
    "    print(f\"DynamoDB table {table_name} created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating DynamoDB table: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'e0b1c859-e841-4e75-97b2-2b285cb38080', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 02 May 2024 14:04:01 GMT', 'content-type': 'application/json', 'content-length': '1316', 'connection': 'keep-alive', 'x-amzn-requestid': 'e0b1c859-e841-4e75-97b2-2b285cb38080'}, 'RetryAttempts': 0}, 'FunctionName': 'a2q1_lambda', 'FunctionArn': 'arn:aws:lambda:us-east-1:102168828713:function:a2q1_lambda', 'Runtime': 'python3.11', 'Role': 'arn:aws:iam::102168828713:role/LabRole', 'Handler': 'q1c_lambda.lambda_handler', 'CodeSize': 1677, 'Description': '', 'Timeout': 300, 'MemorySize': 128, 'LastModified': '2024-05-02T14:04:01.000+0000', 'CodeSha256': 'xSWg7zlvQlWsS90yejTp8n63tKEPF9/mFPzldQYSbuY=', 'Version': '$LATEST', 'TracingConfig': {'Mode': 'PassThrough'}, 'RevisionId': '818d6eef-07d1-4e3d-81c7-c59ff14e1824', 'State': 'Active', 'LastUpdateStatus': 'InProgress', 'LastUpdateStatusReason': 'The function is being created.', 'LastUpdateStatusReasonCode': 'Creating', 'PackageType': 'Zip', 'Architectures': ['x86_64'], 'EphemeralStorage': {'Size': 512}, 'SnapStart': {'ApplyOn': 'None', 'OptimizationStatus': 'Off'}, 'RuntimeVersionConfig': {'RuntimeVersionArn': 'arn:aws:lambda:us-east-1::runtime:1bebe65bb4f19dd8c37baeb0be18a0b278155b42bfe12dd28480199436d18229'}, 'LoggingConfig': {'LogFormat': 'Text', 'LogGroup': '/aws/lambda/a2q1_lambda'}}\n",
      "{'ResponseMetadata': {'RequestId': '6f1a0a22-fbf1-4e96-96c7-6c0518f718fc', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 02 May 2024 14:04:01 GMT', 'content-type': 'application/json', 'content-length': '35', 'connection': 'keep-alive', 'x-amzn-requestid': '6f1a0a22-fbf1-4e96-96c7-6c0518f718fc'}, 'RetryAttempts': 0}, 'ReservedConcurrentExecutions': 10}\n"
     ]
    }
   ],
   "source": [
    "with open('q1c_lambda.zip', 'rb') as f:\n",
    "    lambda_zip = f.read()\n",
    "\n",
    "try:\n",
    "    response = lambda_client.create_function(\n",
    "        FunctionName='a2q1_lambda',\n",
    "        Runtime='python3.11',\n",
    "        Role=role['Role']['Arn'],\n",
    "        Handler='q1c_lambda.lambda_handler',\n",
    "        Code=dict(ZipFile=lambda_zip),\n",
    "        Timeout=300\n",
    ")\n",
    "    print(response)\n",
    "except lambda_client.exceptions.ResourceConflictException:\n",
    "    response = lambda_client.update_function_code(\n",
    "        FunctionName='a2q1_lambda',\n",
    "        ZipFile=lambda_zip\n",
    "        )\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"Error creating or updating Lambda function: {str(e)}\")\n",
    "\n",
    "\n",
    "try:\n",
    "    response = lambda_client.put_function_concurrency(\n",
    "        FunctionName='a2q1_lambda',\n",
    "        ReservedConcurrentExecutions=10\n",
    "    )\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(f\"Error setting concurrency for Lambda function: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import boto3\n",
    "\n",
    "# Create an SQS client\n",
    "sqs_client = boto3.client('sqs')\n",
    "\n",
    "# Specify the name of the queue\n",
    "queue_name = 'a2q1-queue'\n",
    "\n",
    "# Get the URL of the queue\n",
    "queue_url_response = sqs_client.get_queue_url(QueueName=queue_name)\n",
    "queue_url = queue_url_response['QueueUrl']\n",
    "\n",
    "# Get the queue ARN using the queue URL\n",
    "queue_attributes_response = sqs_client.get_queue_attributes(\n",
    "    QueueUrl=queue_url,\n",
    "    AttributeNames=['QueueArn']\n",
    ")\n",
    "queue_arn = queue_attributes_response['Attributes']['QueueArn']\n",
    "\n",
    "sqs_client.set_queue_attributes(\n",
    "    QueueUrl=queue_url,\n",
    "    Attributes={'VisibilityTimeout': '1800'}\n",
    ")\n",
    "\n",
    "response = lambda_client.create_event_source_mapping(\n",
    "    FunctionName='a2q1_lambda',\n",
    "    EventSourceArn=queue_arn,\n",
    "    Enabled=True,\n",
    "    BatchSize=10\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queue created successfully: https://sqs.us-east-1.amazonaws.com/102168828713/a2q1-queue\n",
      "Visibility timeout set successfully.\n",
      "An error occurred: An error occurred (InvalidParameterValueException) when calling the CreateEventSourceMapping operation: Function does not exist\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "# Create an SQS client\n",
    "sqs_client = boto3.client('sqs')\n",
    "lambda_client = boto3.client('lambda')  # Ensure lambda_client is defined\n",
    "\n",
    "# Specify the name of the queue\n",
    "queue_name = 'a2q1-queue'\n",
    "\n",
    "\n",
    "try:\n",
    "    response = sqs_client.create_queue(\n",
    "        QueueName=queue_name\n",
    "    )\n",
    "    print(\"Queue created successfully:\", response['QueueUrl'])\n",
    "except sqs_client.exceptions.QueueNameExists:\n",
    "    print(\"Queue with the same name already exists.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)\n",
    "\n",
    "\n",
    "try:\n",
    "    # Get the URL of the queue\n",
    "    queue_url_response = sqs_client.get_queue_url(QueueName=queue_name)\n",
    "    queue_url = queue_url_response['QueueUrl']\n",
    "\n",
    "    # Get the queue ARN using the queue URL\n",
    "    queue_attributes_response = sqs_client.get_queue_attributes(\n",
    "        QueueUrl=queue_url,\n",
    "        AttributeNames=['QueueArn']\n",
    "    )\n",
    "    queue_arn = queue_attributes_response['Attributes']['QueueArn']\n",
    "\n",
    "    # Set queue attributes\n",
    "    sqs_client.set_queue_attributes(\n",
    "        QueueUrl=queue_url,\n",
    "        Attributes={'VisibilityTimeout': '1800'}\n",
    "    )\n",
    "    print(\"Visibility timeout set successfully.\")\n",
    "\n",
    "    # Create event source mapping between Lambda and the SQS queue\n",
    "    response = lambda_client.create_event_source_mapping(\n",
    "        FunctionName='a2q1_lambda',\n",
    "        EventSourceArn=queue_arn,\n",
    "        Enabled=True,\n",
    "        BatchSize=10\n",
    "    )\n",
    "    print(\"Event source mapping created successfully:\", response)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "json_directory = './test_json'\n",
    "\n",
    "# Iterate over each file in the directory and send it to the SQS queue\n",
    "for filename in os.listdir(json_directory):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(json_directory, filename)\n",
    "        status_code = send_survey(file_path, queue_url)\n",
    "        print(f\"File: {filename}, Status Code: {status_code}\")\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: test1.json, Status Code: 200\n",
      "File: test6.json, Status Code: 200\n",
      "File: test7.json, Status Code: 200\n",
      "File: test8.json, Status Code: 200\n",
      "File: test4.json, Status Code: 200\n",
      "File: test5.json, Status Code: 200\n",
      "File: test9.json, Status Code: 200\n",
      "File: test10.json, Status Code: 200\n",
      "File: test2.json, Status Code: 200\n",
      "File: test3.json, Status Code: 200\n"
     ]
    }
   ],
   "source": [
    "json_directory = './test_json'\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(json_directory):\n",
    "    print(f\"Directory not found: {json_directory}\")\n",
    "else:\n",
    "    # Iterate over each file in the directory and send it to the SQS queue\n",
    "    for filename in os.listdir(json_directory):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(json_directory, filename)\n",
    "            status_code = send_survey(file_path, queue_url)\n",
    "            print(f\"File: {filename}, Status Code: {status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Delete the SQS queue\n",
    "response = sqs_client.delete_queue(QueueUrl=queue_url)\n",
    "print(response)\n",
    "\n",
    "# Specify your bucket and table names\n",
    "\n",
    "# Call the functions to delete the resources\n",
    "s3_client.delete_s3_bucket(bucket_name)\n",
    "sqs_client.delete_dynamodb_table(table_name)\n",
    "lambda_client.delete_function(FunctionName=FunctionName)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to delete SQS Queue: An error occurred (AWS.SimpleQueueService.NonExistentQueue) when calling the DeleteQueue operation: The specified queue does not exist.\n",
      "S3 Bucket deleted successfully\n",
      "DynamoDB Table deleted successfully\n",
      "Failed to delete Lambda Function: An error occurred (ResourceNotFoundException) when calling the DeleteFunction operation: Function not found: arn:aws:lambda:us-east-1:102168828713:function:a2q1_lambda\n"
     ]
    }
   ],
   "source": [
    "# Delete the SQS queue\n",
    "try:\n",
    "    sqs_response = sqs_client.delete_queue(QueueUrl=queue_url)\n",
    "    print(\"SQS Queue deleted successfully:\", sqs_response)\n",
    "except Exception as e:\n",
    "    print(\"Failed to delete SQS Queue:\", str(e))\n",
    "\n",
    "# Delete the S3 bucket and all its contents\n",
    "try:\n",
    "    bucket_objects = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "    if 'Contents' in bucket_objects:\n",
    "        for obj in bucket_objects['Contents']:\n",
    "            s3_client.delete_object(Bucket=bucket_name, Key=obj['Key'])\n",
    "    s3_client.delete_bucket(Bucket=bucket_name)\n",
    "    print(\"S3 Bucket deleted successfully\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to delete S3 Bucket:\", str(e))\n",
    "\n",
    "# Delete the DynamoDB table\n",
    "try:\n",
    "    dynamodb_client.delete_table(TableName=table_name)\n",
    "    print(\"DynamoDB Table deleted successfully\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to delete DynamoDB Table:\", str(e))\n",
    "\n",
    "# Delete the Lambda function\n",
    "try:\n",
    "    lambda_client.delete_function(FunctionName='a2q1_lambda')\n",
    "    print(\"Lambda Function deleted successfully\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to delete Lambda Function:\", str(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
